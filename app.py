

import streamlit as st
from groq import Groq

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. CONFIGURATION DE LA PAGE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ğŸ¤– Mon Assistant Code",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("ğŸ¤– Mon Assistant Code IA")
st.caption("ğŸ’¡ Posez vos questions en Python, JavaScript, HTML, CSS, etc.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. SIDEBAR & CONFIGURATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("âš™ï¸ Configuration")
    
    # Gestion de la clÃ© API
    if "groq_api_key" in st.secrets:
        groq_key = st.secrets["groq_api_key"]
        st.success("âœ… ClÃ© API chargÃ©e")
    else:
        groq_key = st.text_input("ğŸ”‘ ClÃ© API Groq", type="password", placeholder="gsk_...")
        if groq_key and groq_key.startswith("gsk_"):
            st.success("âœ… ClÃ© valide")
    
    st.markdown("[Obtenir une clÃ© gratuite](https://console.groq.com/keys)")
    
    st.divider()
    
    # ğŸ§  SÃ©lecteur de modÃ¨le avec catÃ©gories
    st.subheader("ğŸ§  Choisir un modÃ¨le")
    
    model_category = st.radio(
        "Type de modÃ¨le",
        ["âš¡ Rapide & Ã‰conomique", "ğŸ§  Intelligent & Puissant", "ğŸ”¬ Preview (Tests)", "ğŸ™ï¸ Audio/Vision"],
        horizontal=True,
        label_visibility="collapsed"
    )
    
    # Dictionnaire des modÃ¨les par catÃ©gorie
    models_by_category = {
        "âš¡ Rapide & Ã‰conomique": {
            "llama-3.1-8b-instant": "ğŸ¦™ Llama 3.1 8B (560 t/s) - IdÃ©al pour chat rapide",
        },
        "ğŸ§  Intelligent & Puissant": {
            "llama-3.3-70b-versatile": "ğŸ¦™ Llama 3.3 70B (280 t/s) - Raisonnement complexe",
            "openai/gpt-oss-120b": "ğŸ¤– GPT-OSS 120B (500 t/s) - ModÃ¨le OpenAI puissant",
            "openai/gpt-oss-20b": "ğŸ¤– GPT-OSS 20B (1000 t/s) - Ã‰quilibre vitesse/intelligence",
        },
        "ğŸ”¬ Preview (Tests)": {
            "meta-llama/llama-4-scout-17b-16e-instruct": "ğŸ†• Llama 4 Scout 17B (750 t/s) - Nouvelle gÃ©nÃ©ration",
            "moonshotai/kimi-k2-instruct-0905": "ğŸŒ™ Kimi K2 (200 t/s) - Long contexte (256K)",
            "qwen/qwen3-32b": "ğŸ’¬ Qwen3 32B (400 t/s) - Multilingue performant",
        },
        "ğŸ™ï¸ Audio/Vision": {
            "whisper-large-v3": "ğŸ¤ Whisper Large v3 - Transcription audio",
            "whisper-large-v3-turbo": "ğŸ¤âš¡ Whisper Turbo - Transcription rapide",
        }
    }
    
    # Afficher les modÃ¨les selon la catÃ©gorie sÃ©lectionnÃ©e
    selected_models = models_by_category[model_category]
    model_choice = st.selectbox(
        "SÃ©lectionnez un modÃ¨le",
        list(selected_models.keys()),
        format_func=lambda x: selected_models[x],
        help="Choisissez selon vos besoins : vitesse, intelligence ou fonctionnalitÃ©s spÃ©ciales"
    )
    # ğŸ“Š Indicateur visuel de vitesse
    speed_info = {
        "llama-3.1-8b-instant": "âš¡âš¡âš¡âš¡âš¡ TrÃ¨s rapide",
        "llama-3.3-70b-versatile": "âš¡âš¡âš¡ Rapide",
        "openai/gpt-oss-120b": "âš¡âš¡âš¡âš¡ Rapide",
        "openai/gpt-oss-20b": "âš¡âš¡âš¡âš¡âš¡ TrÃ¨s rapide",
        "meta-llama/llama-4-scout-17b-16e-instruct": "âš¡âš¡âš¡âš¡âš¡ TrÃ¨s rapide",
        "moonshotai/kimi-k2-instruct-0905": "âš¡âš¡ Moyen",
        "qwen/qwen3-32b": "âš¡âš¡âš¡âš¡ Rapide",
    }
    
    if model_choice in speed_info:
        st.caption(f"ğŸš€ Vitesse estimÃ©e : {speed_info[model_choice]}")
    
    # ğŸ“Š Afficher les infos du modÃ¨le sÃ©lectionnÃ©
    st.info(f"ğŸ’¡ {selected_models[model_choice]}")
    if st.sidebar.button("ğŸ”„ RafraÃ®chir les modÃ¨les"):
        try:
            client_test = Groq(api_key=groq_key)
            models = client_test.models.list()
            model_ids = [m.id for m in models.data if 'instant' in m.id or 'versatile' in m.id]
            st.session_state.available_models = model_ids
            st.sidebar.success(f"âœ… {len(model_ids)} modÃ¨les trouvÃ©s")
        except:
            st.session_state.available_models = ["llama-3.1-8b-instant", "llama-3.3-70b-versatile"]

# Utiliser la liste dynamique ou la liste par dÃ©faut
    model_list = st.session_state.get("available_models", ["llama-3.1-8b-instant", "llama-3.3-70b-versatile"])
    model_choice = st.selectbox("ğŸ§  ModÃ¨le IA", model_list)
    st.divider()
    if st.button("ğŸ”¥ RÃ‰INITIALISER COMPLÃˆT", use_container_width=True):
        st.session_state.clear()
        st.rerun()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. GESTION DE L'HISTORIQUE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": "Tu es un expert en code Python."}]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. AFFICHAGE DES MESSAGES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for msg in st.session_state.messages:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. TRAITEMENT DE LA REQUÃŠTE UTILISATEUR
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if prompt := st.chat_input("Pose ta question de code..."):
    
    # VÃ©rification de la clÃ© API
    if not groq_key or not groq_key.startswith("gsk_"):
        st.error("âš ï¸ ClÃ© Groq requise (commenÃ§ant par gsk_)")
        st.stop()
    
    # 1. Afficher le message utilisateur
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # 2. GÃ©nÃ©rer la rÃ©ponse de l'IA
    with st.chat_message("assistant"):
        message_placeholder = st.empty()  # âœ… Placeholder pour mise Ã  jour fluide
        full_response = ""  # âœ… Variable pour accumuler le texte
        
        try:
            client = Groq(api_key=groq_key, timeout=30)
            
            response = client.chat.completions.create(
                model=model_choice,
                messages=st.session_state.messages,
                temperature=0.7,
                max_tokens=2048,
                stream=True  # âœ… Streaming activÃ©
            )
            
            # âœ… BOUCLE MANUELLE : Capture propre du texte chunk par chunk
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    full_response += chunk.choices[0].delta.content
                    message_placeholder.markdown(full_response + "â–Œ")  # Curseur animÃ©
            
            # âœ… Affichage final sans curseur
            message_placeholder.markdown(full_response)
            
            # âœ… Sauvegarder UNIQUEMENT le texte (pas d'objet JSON)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            st.error(f"âŒ Erreur: {str(e)[:200]}")
